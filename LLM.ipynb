{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T16:34:20.881434Z",
     "start_time": "2024-12-10T16:34:20.825419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import tiktoken\n",
    "import sentencepiece as spm\n",
    "import subprocess\n",
    "from tiktoken import _tiktoken as tk\n",
    "import nltk\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "from nltk.corpus import stopwords"
   ],
   "id": "f9a7e8aa1b3814ff",
   "outputs": [],
   "execution_count": 201
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T16:34:20.895433Z",
     "start_time": "2024-12-10T16:34:20.886778Z"
    }
   },
   "cell_type": "code",
   "source": "# !pip freeze > requirements.txt",
   "id": "e67ac312e97d42f",
   "outputs": [],
   "execution_count": 202
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **Dataset**:\n",
    "\n",
    "The Shakespeare dataset contains the complete works of William Shakespeare, including his plays, poems, and sonnets.\n",
    "\n",
    "[**Download link**](https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt)\n",
    "\n",
    "In a character-level language model, each character in the input data is mapped to its respective index from a dictionary. The input to the model is in the form (B, N), where B is the batch size and N is the number of tokens for each sequence. The model was tested with B=N=128, but feel free to explore different values.\n",
    "\n",
    "An interface for the dataset class that takes care of tokenization is provided below.\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CharDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Emits batches of characters.\n",
    "\n",
    "    Adapted from \"https://github.com/karpathy/minGPT\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config, data):\n",
    "\n",
    "        chars = ... # get characters from the input data\n",
    "        self.stoi = { ch:i for i,ch in enumerate(chars) } # map characters to integer indices\n",
    "\n",
    "        ...\n",
    "\n",
    "    def get_vocab_size(self):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def __len__(self):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # grab a chunk of (block_size + 1) characters from the data\n",
    "        # encode every character to an integer\n",
    "        # return the chunk and the shifted version as tensors\n",
    "        pass\n",
    "```\n",
    "\n",
    "\n"
   ],
   "id": "1e7b3b30f73d013f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T16:34:20.907773Z",
     "start_time": "2024-12-10T16:34:20.899031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def check_requirements() -> bool:\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"pip\", \"install\", \"-r\", \"requirements.txt\"],\n",
    "            check=True,  # Raise an exception if the command fails\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            text=True\n",
    "        )\n",
    "        print(result.stdout)  # Optional: Print installation output\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error installing requirements: {e.stderr}\")\n",
    "        return False\n"
   ],
   "id": "359f1802d1cc1390",
   "outputs": [],
   "execution_count": 203
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T16:34:20.913768Z",
     "start_time": "2024-12-10T16:34:20.911097Z"
    }
   },
   "cell_type": "code",
   "source": "# check_requirements()",
   "id": "37422fc4f98dd644",
   "outputs": [],
   "execution_count": 204
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T16:44:59.370845Z",
     "start_time": "2024-12-10T16:44:58.606620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if os.path.exists(\"Dataset.txt\"):\n",
    "    os.system(\"wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\")\n",
    "    os.rename(\"input.txt\", 'Dataset.txt')"
   ],
   "id": "fe02f43f8fac14da",
   "outputs": [],
   "execution_count": 219
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T16:46:51.685509Z",
     "start_time": "2024-12-10T16:46:51.664838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CharDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Emits batches of characters.\n",
    "\n",
    "    Adapted from \"https://github.com/karpathy/minGPT\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data: str, mode: str = \"normal\"):\n",
    "\n",
    "        self.chars = sorted(set(train_text))  # get characters from the input data\n",
    "\n",
    "        self.tokens = set(nltk.word_tokenize(data.lower()))\n",
    "        self.mode = mode\n",
    "\n",
    "        if mode == \"normal\":\n",
    "            self.stoi = {ch: i for i, ch in enumerate(self.chars)}  # map characters to integer indices\n",
    "            self.itos = {i: ch for i, ch in enumerate(self.chars)}  # map integer indices to characters\n",
    "\n",
    "        elif mode == \"sentencepiece\":\n",
    "            spm.SentencePieceTrainer.train(model_prefix='shakespeare', input='Dataset.txt',\n",
    "                                           vocab_size=10770, unk_id=0, bos_id=1, eos_id=2, pad_id=3)\n",
    "\n",
    "\n",
    "        elif mode == \"tiktoken\":\n",
    "            self.enc = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    def encode(self, text):\n",
    "        if self.mode == \"normal\":\n",
    "            return [self.stoi[s] for s in text]\n",
    "        elif self.mode == \"sentencepiece\":\n",
    "            sp = spm.SentencePieceProcessor(model_file='shakespeare.model')\n",
    "            return sp.encode(text)\n",
    "        elif self.mode == \"tiktoken\":\n",
    "            return self.enc.encode(text)\n",
    "\n",
    "    def decode(self, tokens):\n",
    "        if self.mode == \"normal\":\n",
    "            return ''.join([self.itos[t] for t in tokens])\n",
    "        elif self.mode == \"sentencepiece\":\n",
    "            sp = spm.SentencePieceProcessor(model_file='shakespeare.model')\n",
    "            return sp.decode(tokens)\n",
    "        elif self.mode == \"tiktoken\":\n",
    "            return self.enc.decode(tokens)\n",
    "\n",
    "    def get_vocab_size(self):\n",
    "        return len(self.tokens)\n",
    "\n",
    "    def __len__(self):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # grab a chunk of (block_size + 1) characters from the data\n",
    "        # encode every character to an integer\n",
    "        # return the chunk and the shifted version as tensors\n",
    "        pass\n",
    "\n",
    "    # ```"
   ],
   "id": "7bba9bcbc5272509",
   "outputs": [],
   "execution_count": 236
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T16:46:52.012581Z",
     "start_time": "2024-12-10T16:46:52.001533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"Dataset.txt\", \"r\") as file:\n",
    "    train_text = file.read()\n",
    "\n",
    "print(train_text[:500])"
   ],
   "id": "aa83771b2f7c2d6e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor\n"
     ]
    }
   ],
   "execution_count": 237
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T16:47:04.697736Z",
     "start_time": "2024-12-10T16:46:52.310244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "char_dataset1 = CharDataset(train_text, mode=\"normal\")\n",
    "char_dataset2 = CharDataset(train_text, mode=\"sentencepiece\")\n",
    "char_dataset3 = CharDataset(train_text, mode=\"tiktoken\")"
   ],
   "id": "3c69851ade7e8691",
   "outputs": [],
   "execution_count": 238
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T16:47:04.722Z",
     "start_time": "2024-12-10T16:47:04.712715Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Vocabulary size: {char_dataset1.get_vocab_size()}\")",
   "id": "104bb5fc6fc94d70",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 12443\n"
     ]
    }
   ],
   "execution_count": 239
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T16:47:05.564204Z",
     "start_time": "2024-12-10T16:47:04.726505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Length of sequence for normal encoding: {len(char_dataset1.encode(train_text))}\")\n",
    "print(f\"Length of sequence for sentencepiece encoding: {len(char_dataset2.encode(train_text))}\")\n",
    "print(f\"Length of sequence for tiktoken encoding: {len(char_dataset3.encode(train_text))}\")"
   ],
   "id": "8dca0b7739b1d395",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of sequence for normal encoding: 1115394\n",
      "Length of sequence for sentencepiece encoding: 290364\n",
      "Length of sequence for tiktoken encoding: 338025\n"
     ]
    }
   ],
   "execution_count": 240
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T16:47:05.826309Z",
     "start_time": "2024-12-10T16:47:05.566751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = torch.tensor(char_dataset1.encode(train_text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ],
   "id": "a5ca390e5cf5a7fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "execution_count": 241
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T11:07:10.091022Z",
     "start_time": "2024-12-11T11:07:08.798317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data2 = torch.tensor(char_dataset2.encode(train_text), dtype=torch.long)\n",
    "print(data2.shape, data2.dtype)\n",
    "print(data2[:1000])"
   ],
   "id": "378307723b7d6e7a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([290364]) torch.int64\n",
      "tensor([  160,   346,     5,  1001,    54,  1671,   208,   953,     4,   181,\n",
      "           27,   147,     6,   421,     5,   997,     4,   147,     6,   160,\n",
      "          346,     5,   112,    58,    47,  1968,   540,    10,   292,   117,\n",
      "           10,  4422,    19,   421,     5,  7385,     6,  1968,     6,   160,\n",
      "          346,     5,   160,     4,    15,   109,  1602,   479,    26,  1795,\n",
      "          785,    10,     7,   397,     6,   421,     5,   184,   109,     8,\n",
      "           72,     4,    54,   109,     8,    72,     6,   160,   346,     5,\n",
      "          248,    96,   461,    37,     4,    11,    54,     8,    65,    34,\n",
      "         1763,    78,    59,   227,  3029,     6,   244,     8,    72,    16,\n",
      "         7476,    19,   421,     5,   165,    73,  4082,    64,     8,    72,\n",
      "           13,   107,    29,    28,   230,     5,   293,     4,   293,    21,\n",
      "           92,   282,   346,     5,   727,   314,     4,    68,  1339,     6,\n",
      "          160,   346,     5,   184,    58,  7523,   289,  1339,     4,     7,\n",
      "         2571,    68,     6,    69,  1818,  7691,    64,    84,  4491,    96,\n",
      "            5,    74,    89,    84,   855,    96,    44,     7,  6933,     4,\n",
      "          626,    29,   114,  2357,     4,    54,   384,  1376,    89,  4491,\n",
      "           24,    96,  5998,   111,    13,    44,    89,   187,    54,    58,\n",
      "          143,   419,     5,     7,  5515,    22,  2970,    12,    96,     4,\n",
      "            7,  2806,    14,    59,  2033,     4,    26,    40,   126, 10239,\n",
      "         2700,    10,  2025,  8022,    86,  5213,    13,    59,  3862,    26,\n",
      "           16,  1784,    10,    83,   248,    96,   776,    36,    30,    59,\n",
      "         5599,     4,   467,    54,   903,    18,  7729,     5,    32,     7,\n",
      "          599,   109,     9,   147,    36,    20,  4617,    32,  3111,     4,\n",
      "           25,    20,  4328,    32,   776,     6,    92,   282,   346,     5,\n",
      "          523,    15,  1671,  1232,  4262,   334,  1602,   479,    19,   421,\n",
      "            5,    66,   689,    37,   365,     5,    35,     8,    12,    16,\n",
      "          238,  1261,    10,     7,   714,  7982,     6,    92,   282,   346,\n",
      "            5,   120,  4766,    15,    63,  2123,    35,   530,   230,    32,\n",
      "           33,   620,    19,   160,   346,     5,  2315,   141,   101,    13,\n",
      "           11,   388,    28,   743,    10,   162,    37,    68,   734,    32,\n",
      "           72,     4,    44,    22,    35,  1087,    12,   353,    30,   262,\n",
      "          580,     6,    92,   282,   346,     5,   323,     4,    44,   147,\n",
      "           25,  6050,   111,     6,   160,   346,     5,     9,    95,   361,\n",
      "           15,     4,    63,    35,   106,   230,  7337,     4,    35,   137,\n",
      "           29,    10,    22,   524,     5,   372,  1093,    39,  8907,    24,\n",
      "          204,   167,    28,   743,    10,    95,    29,    81,    32,    33,\n",
      "          620,    35,   137,    29,    10,   490,    33,   283,    11,    10,\n",
      "           28,   363,   111,   580,    13,   129,    35,    26,     4,   529,\n",
      "          371,     7,    16,  9775,    14,    33,   945,     6,    92,   282,\n",
      "          346,     5,    69,    35,   214,   458,    20,    33,   588,     4,\n",
      "           15,  1527,    16,  1519,    20,    37,     6,   112,   116,    20,\n",
      "           61,   251,    95,    35,    26,  5537,   491,     6,   160,   346,\n",
      "            5,   132,     9,   116,    25,     4,     9,   442,    25,    28,\n",
      "         2562,    14,  5872,    13,    35,   106,  1126,     4,    30,  6751,\n",
      "            4,    10,  4031,    20,  4386,     6,    69,  5748,    58,   163,\n",
      "           19,    45,   270,   861,   201,     8,     7,   617,    26,  1398,\n",
      "          153,     5,   415,   310,    54,  3820,    91,    19,    10,     7,\n",
      "         1683,    21,   421,     5,   177,     4,    98,     6,   160,   346,\n",
      "            5,  3142,    21,   236,   308,    91,    19,    92,   282,   346,\n",
      "            5,  2265,   141,  1684,  8775,  7840,   644,    13,   103,    22,\n",
      "          106,  1625,  1100,     7,   397,     6,   160,   346,     5,   127,\n",
      "            8,    12,   103,   864,   576,     5,    84,    47,     7,   355,\n",
      "          114,    41,    21,    18,   303,   267,   100,     5,    69,   832,\n",
      "            8,    12,     4,    17,  2796,     4,    20,   217,    19,   215,\n",
      "          131,    15,   152,  5745,    11,  7326,    19,    45,   550,    19,\n",
      "          147,     4,     9,   307,    15,     6,   160,   346,     5,   456,\n",
      "          546,    26,    25,  2193,    10,     7,  1608,    13,    89,    34,\n",
      "          128,    20,  9781,    36,    32,    72,   890,    63,    54,  1876,\n",
      "           10,    57,     4,   129,    75,    54,     8,    65,   431,    52,\n",
      "         1057,    20,  1082,     6,   430,    95,   289,  3152,    34,   975,\n",
      "         6245,     5,    89,    55,   109,    54,    34,   975,   568,   143,\n",
      "            6,    18,   303,   267,   100,     5,   156,     4,  1489,     4,\n",
      "           17,    68,   305,     4,   154,   864,  3563,     4,   396,    15,\n",
      "         3589,  1333,    19,   160,   346,     5,   184,   214,     4,    79,\n",
      "            4,    54,    58,  1811,   979,     6,    18,   303,   267,   100,\n",
      "            5,     9,   180,    15,     4,   305,     4,   188,  6376,   946,\n",
      "          692,   370,     7,  2571,    14,    15,     6,    77,    31,  2273,\n",
      "            4,   207,  4019,    20,    36,  4056,     4,    15,   110,    40,\n",
      "          101,  2983,    78,     7,   274,    30,    31,  8351,  6336,    40,\n",
      "         2841,    83,    66,   689,     7,  1084,   457,     4,   440,   862,\n",
      "           42,    64,    45,   251,    29,  3592,     4,  1877,    51,   896,\n",
      "          484,  5711,   175,    73,   975,  4546,  7299,   117,   167,   298,\n",
      "         3360,    20,    31,  4371,     6,    77,     7,  4056,     4,    45,\n",
      "          599,     4,    25,     7,  2571,     4,   108,    29,     4,    11,\n",
      "          207,  1345,    10,    83,     4,    25,   568,     4,   116,   458,\n",
      "            6,  1481,     4,   112,    58,  4562,    53,  3756,  1032,  1310,\n",
      "          215,    73,   965,    12,    15,     4,    11,    15,  1166,    45,\n",
      "         5852,   201,     8,     7,   457,     4,   236,   692,    32,    15,\n",
      "          122,  2876,     4,   234,    15,   850,    83,    40,   900,     6,\n",
      "          160,   346,     5,   120,  3191,    32,    96,    21,  1557,     4,\n",
      "          516,    21,   430,   635,     8,    80,   692,    24,    32,    96,\n",
      "          142,     5,  1104,    96,    10,  4422,     4,    11,    86,  2160,\n",
      "           39, 10413,  3207,  8923,    30,  2710,    13,   108,  5297,    12,\n",
      "           32,    96,  8069,     4,    10,  3523,  4601,    12,    13,  2535,\n",
      "         2353,   208,  2357,  1267,  5239,    88,   334,     7,   895,     4,\n",
      "           11,  2957,    73,  3265,    51,  3915,  2353,     4,    10,  5141,\n",
      "          144,    11,  3408,     7,   289,     6,   132,     7,  1069,  1440,\n",
      "           96,    25,   144,     4,    89,    42,    13,    11,   125,     8,\n",
      "           12,    47,     7,    93,    89,   294,    96,     6,    18,   303,\n",
      "          267,   100,     5,   347,  1310,    15,   116,  3747,  1333,  2744,\n",
      "         6050,     4,   212,    28,  2419,    14,  2041,     6,     9,    55,\n",
      "          180,    15,    66,  1140,   858,     5,    29,   110,    28,    15,\n",
      "           34,   455,    29,    13,    67,     4,   447,    29,  2278,    17,\n",
      "          696,     4,     9,    42,  3876,    46,  3050,    52,    72,    16,\n",
      "          336,    73,     6,   160,   346,     5,   319,     4,     9,     8,\n",
      "           65,   181,    29,     4,    79,     5,   142,    15,   116,    25,\n",
      "          187,    10,  2111,  2257,   332,    59,  2507,    30,    16,   858,\n",
      "            5,    44,     4,   126,    52,    72,   490,    15,     4,   881,\n",
      "            6,    18,   303,   267,   100,     5,   342,    81,    16,   155,\n",
      "          149,    47,     7,   508,     8,    12,  3443,  7126,     8,    24])\n"
     ]
    }
   ],
   "execution_count": 257
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T11:11:08.423751Z",
     "start_time": "2024-12-11T11:11:08.393309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n = int(0.9 * len(data))\n",
    "\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ],
   "id": "b42876778837d857",
   "outputs": [],
   "execution_count": 269
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cb485da255ca58cb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
