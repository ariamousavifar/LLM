{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T16:34:20.881434Z",
     "start_time": "2024-12-10T16:34:20.825419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import tiktoken\n",
    "import sentencepiece as spm\n",
    "import subprocess\n",
    "from tiktoken import _tiktoken as tk\n",
    "import nltk\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "from nltk.corpus import stopwords"
   ],
   "id": "f9a7e8aa1b3814ff",
   "outputs": [],
   "execution_count": 201
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T16:34:20.895433Z",
     "start_time": "2024-12-10T16:34:20.886778Z"
    }
   },
   "cell_type": "code",
   "source": "# !pip freeze > requirements.txt",
   "id": "e67ac312e97d42f",
   "outputs": [],
   "execution_count": 202
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **Dataset**:\n",
    "\n",
    "The Shakespeare dataset contains the complete works of William Shakespeare, including his plays, poems, and sonnets.\n",
    "\n",
    "[**Download link**](https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt)\n",
    "\n",
    "In a character-level language model, each character in the input data is mapped to its respective index from a dictionary. The input to the model is in the form (B, N), where B is the batch size and N is the number of tokens for each sequence. The model was tested with B=N=128, but feel free to explore different values.\n",
    "\n",
    "An interface for the dataset class that takes care of tokenization is provided below.\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CharDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Emits batches of characters.\n",
    "\n",
    "    Adapted from \"https://github.com/karpathy/minGPT\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config, data):\n",
    "\n",
    "        chars = ... # get characters from the input data\n",
    "        self.stoi = { ch:i for i,ch in enumerate(chars) } # map characters to integer indices\n",
    "\n",
    "        ...\n",
    "\n",
    "    def get_vocab_size(self):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def __len__(self):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # grab a chunk of (block_size + 1) characters from the data\n",
    "        # encode every character to an integer\n",
    "        # return the chunk and the shifted version as tensors\n",
    "        pass\n",
    "```\n",
    "\n",
    "\n"
   ],
   "id": "1e7b3b30f73d013f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T16:34:20.907773Z",
     "start_time": "2024-12-10T16:34:20.899031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def check_requirements() -> bool:\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"pip\", \"install\", \"-r\", \"requirements.txt\"],\n",
    "            check=True,  # Raise an exception if the command fails\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            text=True\n",
    "        )\n",
    "        print(result.stdout)  # Optional: Print installation output\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error installing requirements: {e.stderr}\")\n",
    "        return False\n"
   ],
   "id": "359f1802d1cc1390",
   "outputs": [],
   "execution_count": 203
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T16:34:20.913768Z",
     "start_time": "2024-12-10T16:34:20.911097Z"
    }
   },
   "cell_type": "code",
   "source": "# check_requirements()",
   "id": "37422fc4f98dd644",
   "outputs": [],
   "execution_count": 204
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T16:34:20.940374Z",
     "start_time": "2024-12-10T16:34:20.935624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if not os.path.exists(\"Dataset.txt\"):\n",
    "    os.system(\"wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\")\n",
    "    os.rename(\"input.txt\", 'Dataset.txt')"
   ],
   "id": "fe02f43f8fac14da",
   "outputs": [],
   "execution_count": 205
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T16:34:21.014146Z",
     "start_time": "2024-12-10T16:34:20.984316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CharDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Emits batches of characters.\n",
    "\n",
    "    Adapted from \"https://github.com/karpathy/minGPT\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data: str, mode: str = \"normal\"):\n",
    "\n",
    "        self.chars = set(train_text)  # get characters from the input data\n",
    "        self.tokens = set(nltk.word_tokenize(data.lower()))\n",
    "        self.mode = mode\n",
    "\n",
    "        if mode == \"normal\":\n",
    "            self.stoi = {ch: i for i, ch in enumerate(self.chars)}  # map characters to integer indices\n",
    "            self.itos = {i: ch for i, ch in enumerate(self.chars)}  # map integer indices to characters\n",
    "\n",
    "        elif mode == \"sentencepiece\":\n",
    "            spm.SentencePieceTrainer.train(model_prefix='shakespeare', input='Dataset.txt',\n",
    "                                           vocab_size=10770, unk_id=0, bos_id=1, eos_id=2, pad_id=3)\n",
    "\n",
    "\n",
    "        elif mode == \"tiktoken\":\n",
    "            self.enc = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    def encode(self, text):\n",
    "        if self.mode == \"normal\":\n",
    "            return [self.stoi[s] for s in text]\n",
    "        elif self.mode == \"sentencepiece\":\n",
    "            sp = spm.SentencePieceProcessor(model_file='shakespeare.model')\n",
    "            return sp.encode(text)\n",
    "        elif self.mode == \"tiktoken\":\n",
    "            return self.enc.encode(text)\n",
    "\n",
    "    def decode(self, tokens):\n",
    "        if self.mode == \"normal\":\n",
    "            return ''.join([self.itos[t] for t in tokens])\n",
    "        elif self.mode == \"sentencepiece\":\n",
    "            sp = spm.SentencePieceProcessor(model_file='shakespeare.model')\n",
    "            return sp.decode(tokens)\n",
    "        elif self.mode == \"tiktoken\":\n",
    "            return self.enc.decode(tokens)\n",
    "\n",
    "    def get_vocab_size(self):\n",
    "        return len(self.tokens)\n",
    "\n",
    "    def __len__(self):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # grab a chunk of (block_size + 1) characters from the data\n",
    "        # encode every character to an integer\n",
    "        # return the chunk and the shifted version as tensors\n",
    "        pass\n",
    "\n",
    "    # ```"
   ],
   "id": "7bba9bcbc5272509",
   "outputs": [],
   "execution_count": 206
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T16:34:21.067382Z",
     "start_time": "2024-12-10T16:34:21.057306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"Dataset.txt\", \"r\") as file:\n",
    "    train_text = file.read()\n",
    "\n",
    "print(train_text[:500])"
   ],
   "id": "aa83771b2f7c2d6e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor\n"
     ]
    }
   ],
   "execution_count": 207
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T16:34:29.143385Z",
     "start_time": "2024-12-10T16:34:21.071328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "char_dataset1 = CharDataset(train_text, mode=\"normal\")\n",
    "char_dataset2 = CharDataset(train_text, mode=\"sentencepiece\")\n",
    "char_dataset3 = CharDataset(train_text, mode=\"tiktoken\")"
   ],
   "id": "3c69851ade7e8691",
   "outputs": [],
   "execution_count": 208
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T16:34:29.151398Z",
     "start_time": "2024-12-10T16:34:29.146822Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Vocabulary size: {char_dataset1.get_vocab_size()}\")",
   "id": "104bb5fc6fc94d70",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 12443\n"
     ]
    }
   ],
   "execution_count": 209
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T16:34:30.137402Z",
     "start_time": "2024-12-10T16:34:29.154931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Length of sequence for normal encoding: {len(char_dataset1.encode(train_text))}\")\n",
    "print(f\"Length of sequence for sentencepiece encoding: {len(char_dataset2.encode(train_text))}\")\n",
    "print(f\"Length of sequence for tiktoken encoding: {len(char_dataset3.encode(train_text))}\")"
   ],
   "id": "8dca0b7739b1d395",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of sequence for normal encoding: 1115394\n",
      "Length of sequence for sentencepiece encoding: 290364\n",
      "Length of sequence for tiktoken encoding: 338025\n"
     ]
    }
   ],
   "execution_count": 210
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
