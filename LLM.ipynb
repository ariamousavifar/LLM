{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T16:31:42.786627Z",
     "start_time": "2024-12-10T16:31:42.775891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import tiktoken\n",
    "import sentencepiece as spm\n",
    "import subprocess\n",
    "from tiktoken import _tiktoken as tk\n",
    "import nltk\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "from nltk.corpus import stopwords"
   ],
   "id": "f9a7e8aa1b3814ff",
   "outputs": [],
   "execution_count": 191
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T16:31:42.833777Z",
     "start_time": "2024-12-10T16:31:42.827783Z"
    }
   },
   "cell_type": "code",
   "source": "# !pip freeze > requirements.txt",
   "id": "e67ac312e97d42f",
   "outputs": [],
   "execution_count": 192
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **Dataset**:\n",
    "\n",
    "The Shakespeare dataset contains the complete works of William Shakespeare, including his plays, poems, and sonnets.\n",
    "\n",
    "[**Download link**](https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt)\n",
    "\n",
    "In a character-level language model, each character in the input data is mapped to its respective index from a dictionary. The input to the model is in the form (B, N), where B is the batch size and N is the number of tokens for each sequence. The model was tested with B=N=128, but feel free to explore different values.\n",
    "\n",
    "An interface for the dataset class that takes care of tokenization is provided below.\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CharDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Emits batches of characters.\n",
    "\n",
    "    Adapted from \"https://github.com/karpathy/minGPT\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config, data):\n",
    "\n",
    "        chars = ... # get characters from the input data\n",
    "        self.stoi = { ch:i for i,ch in enumerate(chars) } # map characters to integer indices\n",
    "\n",
    "        ...\n",
    "\n",
    "    def get_vocab_size(self):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def __len__(self):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # grab a chunk of (block_size + 1) characters from the data\n",
    "        # encode every character to an integer\n",
    "        # return the chunk and the shifted version as tensors\n",
    "        pass\n",
    "```\n",
    "\n",
    "\n"
   ],
   "id": "1e7b3b30f73d013f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T16:31:43.049296Z",
     "start_time": "2024-12-10T16:31:42.848489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def check_requirements() -> bool:\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"pip\", \"install\", \"-r\", \"requirements.txt\"],\n",
    "            check=True,  # Raise an exception if the command fails\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            text=True\n",
    "        )\n",
    "        print(result.stdout)  # Optional: Print installation output\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error installing requirements: {e.stderr}\")\n",
    "        return False\n"
   ],
   "id": "359f1802d1cc1390",
   "outputs": [],
   "execution_count": 193
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T16:31:55.190574Z",
     "start_time": "2024-12-10T16:31:43.054042Z"
    }
   },
   "cell_type": "code",
   "source": "check_requirements()",
   "id": "37422fc4f98dd644",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==2.0.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (2.0.2)\n",
      "Requirement already satisfied: sentencepiece==0.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (0.2.0)\n",
      "Requirement already satisfied: tiktoken==0.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (0.6.0)\n",
      "Requirement already satisfied: torch==2.2.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (2.2.2)\n",
      "Requirement already satisfied: torchaudio==2.2.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (2.2.2)\n",
      "Requirement already satisfied: torchvision==0.17.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (0.17.2)\n",
      "Collecting nltk==3.8.1 (from -r requirements.txt (line 7))\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tiktoken==0.6.0->-r requirements.txt (line 3)) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tiktoken==0.6.0->-r requirements.txt (line 3)) (2.32.3)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch==2.2.2->-r requirements.txt (line 4)) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch==2.2.2->-r requirements.txt (line 4)) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch==2.2.2->-r requirements.txt (line 4)) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch==2.2.2->-r requirements.txt (line 4)) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch==2.2.2->-r requirements.txt (line 4)) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch==2.2.2->-r requirements.txt (line 4)) (2024.9.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torchvision==0.17.2->-r requirements.txt (line 6)) (10.4.0)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nltk==3.8.1->-r requirements.txt (line 7)) (8.1.7)\n",
      "Collecting joblib (from nltk==3.8.1->-r requirements.txt (line 7))\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nltk==3.8.1->-r requirements.txt (line 7)) (4.67.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken==0.6.0->-r requirements.txt (line 3)) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken==0.6.0->-r requirements.txt (line 3)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken==0.6.0->-r requirements.txt (line 3)) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken==0.6.0->-r requirements.txt (line 3)) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2->torch==2.2.2->-r requirements.txt (line 4)) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sympy->torch==2.2.2->-r requirements.txt (line 4)) (1.3.0)\n",
      "Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Installing collected packages: joblib, nltk\n",
      "Successfully installed joblib-1.4.2 nltk-3.8.1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 194
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T16:31:55.205202Z",
     "start_time": "2024-12-10T16:31:55.196730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if not os.path.exists(\"Dataset.txt\"):\n",
    "    os.system(\"wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\")\n",
    "    os.rename(\"input.txt\", 'Dataset.txt')"
   ],
   "id": "fe02f43f8fac14da",
   "outputs": [],
   "execution_count": 195
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T16:31:55.228802Z",
     "start_time": "2024-12-10T16:31:55.210395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CharDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Emits batches of characters.\n",
    "\n",
    "    Adapted from \"https://github.com/karpathy/minGPT\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data: str, mode: str = \"normal\"):\n",
    "\n",
    "        self.chars = set(train_text)  # get characters from the input data\n",
    "        self.tokens = set(nltk.word_tokenize(data.lower()))\n",
    "        self.mode = mode\n",
    "\n",
    "        if mode == \"normal\":\n",
    "            self.stoi = {ch: i for i, ch in enumerate(self.chars)}  # map characters to integer indices\n",
    "            self.itos = {i: ch for i, ch in enumerate(self.chars)}  # map integer indices to characters\n",
    "\n",
    "        elif mode == \"sentencepiece\":\n",
    "            spm.SentencePieceTrainer.train(model_prefix='shakespeare', input='Dataset.txt',\n",
    "                                           vocab_size=10770, unk_id=0, bos_id=1, eos_id=2, pad_id=3)\n",
    "\n",
    "\n",
    "        elif mode == \"tiktoken\":\n",
    "            self.enc = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    def encode(self, text):\n",
    "        if self.mode == \"normal\":\n",
    "            return [self.stoi[s] for s in text]\n",
    "        elif self.mode == \"sentencepiece\":\n",
    "            sp = spm.SentencePieceProcessor(model_file='shakespeare.model')\n",
    "            return sp.encode(text)\n",
    "        elif self.mode == \"tiktoken\":\n",
    "            return self.enc.encode(text)\n",
    "\n",
    "    def decode(self, tokens):\n",
    "        if self.mode == \"normal\":\n",
    "            return ''.join([self.itos[t] for t in tokens])\n",
    "        elif self.mode == \"sentencepiece\":\n",
    "            sp = spm.SentencePieceProcessor(model_file='shakespeare.model')\n",
    "            return sp.decode(tokens)\n",
    "        elif self.mode == \"tiktoken\":\n",
    "            return self.enc.decode(tokens)\n",
    "\n",
    "    def get_vocab_size(self):\n",
    "        return len(self.tokens)\n",
    "\n",
    "    def __len__(self):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # grab a chunk of (block_size + 1) characters from the data\n",
    "        # encode every character to an integer\n",
    "        # return the chunk and the shifted version as tensors\n",
    "        pass\n",
    "\n",
    "    # ```"
   ],
   "id": "7bba9bcbc5272509",
   "outputs": [],
   "execution_count": 196
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T16:31:55.251371Z",
     "start_time": "2024-12-10T16:31:55.233433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"Dataset.txt\", \"r\") as file:\n",
    "    train_text = file.read()\n",
    "\n",
    "print(train_text[:500])"
   ],
   "id": "aa83771b2f7c2d6e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor\n"
     ]
    }
   ],
   "execution_count": 197
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T16:32:02.975766Z",
     "start_time": "2024-12-10T16:31:55.255552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "char_dataset1 = CharDataset(train_text, mode=\"normal\")\n",
    "char_dataset2 = CharDataset(train_text, mode=\"sentencepiece\")\n",
    "char_dataset3 = CharDataset(train_text, mode=\"tiktoken\")"
   ],
   "id": "3c69851ade7e8691",
   "outputs": [],
   "execution_count": 198
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T16:32:02.983472Z",
     "start_time": "2024-12-10T16:32:02.977507Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Vocabulary size: {char_dataset1.get_vocab_size()}\")",
   "id": "104bb5fc6fc94d70",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 12443\n"
     ]
    }
   ],
   "execution_count": 199
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T16:32:04.413029Z",
     "start_time": "2024-12-10T16:32:02.988656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Length of sequence for normal encoding: {len(char_dataset1.encode(train_text))}\")\n",
    "print(f\"Length of sequence for sentencepiece encoding: {len(char_dataset2.encode(train_text))}\")\n",
    "print(f\"Length of sequence for tiktoken encoding: {len(char_dataset3.encode(train_text))}\")"
   ],
   "id": "8dca0b7739b1d395",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of sequence for normal encoding: 1115394\n",
      "Length of sequence for sentencepiece encoding: 290364\n",
      "Length of sequence for tiktoken encoding: 338025\n"
     ]
    }
   ],
   "execution_count": 200
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
